{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e689a72-629c-426f-8b44-26a1f7183001",
   "metadata": {},
   "source": [
    "# Extract Sentiment from Filtered Tweets by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4242a0-5acd-4040-9d6e-8ad45015a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214ed139-be11-43c0-8020-7a0d49e3a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ceac9d-63a2-4acd-8978-a3b144c80ba4",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16473c34-9086-4ee8-8a6f-a1e82845959d",
   "metadata": {},
   "source": [
    "Extract sentiment from text in tweet using pre-trained transformer models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ef865-6ca2-45f3-874f-0dcca8ba54f5",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8aeaf8-523b-4c9e-a683-94f39ecb9a50",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "raw_data_folder = \"data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efca00d3-d918-410a-88fa-bc71b9328c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = [glob(f\"{raw_data_folder}/*.parquet.gzip\")[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce6dcd6-0913-43e6-bf2d-d086f7cba043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_whitespace(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop tweets with duplicated text.\"\"\"\n",
    "    df[\"text\"] = df[\"text\"].str.lstrip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_duplicate_tweets(\n",
    "    df: pd.DataFrame, subset: List[str] = [\"text\"]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Drop tweets with duplicated text.\"\"\"\n",
    "    df_no_dups = df.drop_duplicates(subset=subset)\n",
    "    num_rows_dropped = len(df) - len(df_no_dups)\n",
    "    print(f\"Dropped {num_rows_dropped:,} duplicated tweets from raw data\")\n",
    "    return df_no_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d3ae5-1e61-4cbc-8bef-4f4f1a5a3a79",
   "metadata": {},
   "source": [
    "## Extract Sentiment from Hourly Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae77e33-ddad-47d7-b204-81753c05da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Sentiment from Tweets - Starting time = 2022-08-13 17:02:31.859...\n",
      "Dropped 813 duplicated tweets from raw data\n",
      "Done extracting sentiment at 2022-08-13 17:02:31.866 (0.007 seconds).\n",
      "CPU times: user 7.99 ms, sys: 0 ns, total: 7.99 ms\n",
      "Wall time: 6.67 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huge day ahead for the NASA/ESA/CSA  with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With today's clearing skies, the NASA MODIS sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By the way, the clips I’m posting each day of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hubble had quite a year, but perhaps one its b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OH MY GOODNESS!!It's there!A semi clear sky to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>\"Our goal is to create a safe &amp;amp; transparen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>It went up, cause if she has to run, there is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>This has been my year in astronomy and   In 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>Come on man, Arecibo was long defunct and they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>Ms. Sayhoushi Jinsoku Ryan takes a mission to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     Huge day ahead for the NASA/ESA/CSA  with the ...\n",
       "1     With today's clearing skies, the NASA MODIS sa...\n",
       "3     By the way, the clips I’m posting each day of ...\n",
       "4     Hubble had quite a year, but perhaps one its b...\n",
       "5     OH MY GOODNESS!!It's there!A semi clear sky to...\n",
       "...                                                 ...\n",
       "1127  \"Our goal is to create a safe &amp; transparen...\n",
       "1130  It went up, cause if she has to run, there is ...\n",
       "1131  This has been my year in astronomy and   In 20...\n",
       "1134  Come on man, Arecibo was long defunct and they...\n",
       "1139  Ms. Sayhoushi Jinsoku Ryan takes a mission to ...\n",
       "\n",
       "[353 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for q, f in enumerate(files_list):\n",
    "    start = datetime.now()\n",
    "    print(\n",
    "        \"Extracting Sentiment from Tweets - Starting time = \"\n",
    "        f\"{start.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}...\"\n",
    "    )\n",
    "    df_raw = pd.read_parquet(f, columns=['text'])\n",
    "    df = (\n",
    "        df_raw.pipe(remove_leading_whitespace)\n",
    "        .pipe(drop_duplicate_tweets, subset=['text'])\n",
    "    )\n",
    "    end = datetime.now()\n",
    "    duration = (end - start).total_seconds()\n",
    "    print(\n",
    "        \"Done extracting sentiment at \"\n",
    "        f\"{end.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]} ({duration:.3f} seconds).\"\n",
    "    )\n",
    "    if q < len(files_list)-1:\n",
    "        print()\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
