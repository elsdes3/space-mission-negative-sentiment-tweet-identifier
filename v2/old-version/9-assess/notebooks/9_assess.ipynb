{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4db6969-f236-42f7-94e2-06c1e0cd1ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9367cc83-ebdb-4dce-8125-8c07228eb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba93e639-bea7-4d5f-ad2d-158589d1f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822879a6-60ef-4fb6-93f3-b49d09fb94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = os.path.join(os.pardir)\n",
    "src_dir = os.path.join(PROJ_ROOT, \"src\")\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b1a526a-7fc7-47e4-9496-9fec547e3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport metrics_utils\n",
    "from metrics_utils import calculate_metrics\n",
    "\n",
    "%aimport s3_utils\n",
    "from s3_utils import download_files_from_s3, upload_file_to_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170f133-bba1-4676-8bc1-09be999e2878",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945152b-2421-4887-9127-5c09a1d1f5e4",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd297e-d8b4-49ba-bf13-9b0f5a2f37f3",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec3add5a-97ed-444c-b77b-344264d5f43b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# raw data on S3\n",
    "path_to_folder = \"/datasets/twitter/kinesis-demo/\"\n",
    "\n",
    "# processed data\n",
    "processed_data_dir = \"../data/processed\"\n",
    "\n",
    "label_mapper = {\"does_not_need_support\": 0, \"needs_support\": 1}\n",
    "\n",
    "needs_support_labels = [0, 1]\n",
    "\n",
    "model_output_dir = \"../model-fine-tuned\"\n",
    "\n",
    "# Metadata - feature engineering\n",
    "b = [0, 4, 8, 12, 16, 20, 24]\n",
    "l = [\"Late Night\", \"Early Morning\", \"Morning\", \"Afternoon\", \"Evening\", \"Night\"]\n",
    "\n",
    "upload_to_s3 = True\n",
    "cleanup_local_files = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe0a5c11-2871-4b6f-878e-8145b1c551b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved AWS credentials from .env file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'does_not_need_support', 1: 'needs_support'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_bucket_name = os.getenv(\"AWS_S3_BUCKET_NAME\", \"\")\n",
    "\n",
    "try:\n",
    "    session = boto3.Session(profile_name=\"default\")\n",
    "    s3_client = session.client(\"s3\")\n",
    "    aws_region = session.region_name\n",
    "    print(\"Retrieved AWS credentials from ~/.ssh/aws file\")\n",
    "except Exception as e:\n",
    "    if str(e) == \"The config profile (default) could not be found\":\n",
    "        aws_region = os.getenv(\"AWS_REGION\")\n",
    "        s3_client = boto3.client(\"s3\", region_name=aws_region)\n",
    "        print(\"Retrieved AWS credentials from .env file\")\n",
    "\n",
    "dtypes_dict = {\n",
    "    \"id\": pd.StringDtype(),\n",
    "    \"contributors\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"source_text\": pd.StringDtype(),\n",
    "    \"place_country\": pd.StringDtype(),\n",
    "    \"user_location\": pd.StringDtype(),\n",
    "    \"user_followers\": pd.Int32Dtype(),\n",
    "    \"user_friends\": pd.Int32Dtype(),\n",
    "    \"user_listed\": pd.Int32Dtype(),\n",
    "    \"user_favourites\": pd.Int32Dtype(),\n",
    "    \"user_statuses\": pd.Int32Dtype(),\n",
    "    \"user_protected\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"user_verified\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"is_quote_status\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"retweeted\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"retweeted_tweet\": pd.StringDtype(),\n",
    "    \"in_reply_to_screen_name\": pd.StringDtype(),\n",
    "    \"user_screen_name\": pd.StringDtype(),\n",
    "    \"num_urls_in_tweet_text\": pd.Int32Dtype(),\n",
    "    \"num_words\": pd.Int32Dtype(),\n",
    "    \"text\": pd.StringDtype(),\n",
    "    \"sentiment\": pd.Int32Dtype(),\n",
    "    \"order\": pd.Int32Dtype(),\n",
    "    \"hour\": pd.Int32Dtype(),\n",
    "    \"day\": pd.Int32Dtype(),\n",
    "    \"weekday\": pd.StringDtype(),\n",
    "    \"time_of_day\": pd.StringDtype(),\n",
    "    \"batch_num\": pd.Int32Dtype(),\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label_mapper.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c64029-a263-48cb-98e5-701042bab9a3",
   "metadata": {},
   "source": [
    "## Get Hourly Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3736938-017c-4bc1-8cfc-55f833e4ed3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found at ../data/processed/test_nlp__inference_starts_20220110_000000.xlsx. Did nothing.\n",
      "File found at ../data/processed/train_nlp__inference_starts_20220110_000000.xlsx. Did nothing.\n",
      "File found at ../data/processed/val_nlp__inference_starts_20220110_000000.xlsx. Did nothing.\n",
      "../data/processed/test_nlp__inference_starts_20220110_000000.xlsx\n",
      "CPU times: user 12.3 ms, sys: 221 µs, total: 12.5 ms\n",
      "Wall time: 176 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/processed/test_nlp__inference_starts_20220110_000000.xlsx',\n",
       " '../data/processed/train_nlp__inference_starts_20220110_000000.xlsx',\n",
       " '../data/processed/val_nlp__inference_starts_20220110_000000.xlsx']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "download_files_from_s3(\n",
    "    s3_client,\n",
    "    s3_bucket_name,\n",
    "    processed_data_dir,\n",
    "    aws_region,\n",
    "    f\"{path_to_folder[1:]}processed/nlp_splits/\",\n",
    "    \".xlsx\",\n",
    ")\n",
    "proc_files = sorted(glob(f\"{processed_data_dir}/*_nlp_*.xlsx\"))\n",
    "proc_file_inference = [f for f in proc_files if \"test_\" in f][0]\n",
    "print(proc_file_inference)\n",
    "proc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0396a241-e8c0-4463-aa32-6574d5d60475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found at ../data/processed/test_nlp__inference_starts_20220110_000000__batch_1__with_preds.parquet.gzip. Did nothing.\n",
      "CPU times: user 16.8 ms, sys: 700 µs, total: 17.5 ms\n",
      "Wall time: 190 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/processed/test_nlp__inference_starts_20220110_000000__batch_1__with_preds.parquet.gzip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "download_files_from_s3(\n",
    "    s3_client,\n",
    "    s3_bucket_name,\n",
    "    processed_data_dir,\n",
    "    aws_region,\n",
    "    f\"{path_to_folder[1:]}processed/nlp_splits/test_\",\n",
    "    \".parquet.gzip\",\n",
    ")\n",
    "infer_file_with_pred = sorted(glob(f\"{processed_data_dir}/*.parquet.gzip\"))[-1]\n",
    "infer_file_with_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67f037-84ce-4a87-91a0-84588e17f7ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d650f553-ed9a-49ca-bce5-409e4da940ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>contributors</th>\n",
       "      <th>user_joined</th>\n",
       "      <th>source_text</th>\n",
       "      <th>place_country</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_listed</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_statuses</th>\n",
       "      <th>user_protected</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_tweet</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>num_urls_in_tweet_text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>order</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>split</th>\n",
       "      <th>pred</th>\n",
       "      <th>error</th>\n",
       "      <th>created_at_hour</th>\n",
       "      <th>created_at_day</th>\n",
       "      <th>user_joined_hour</th>\n",
       "      <th>user_joined_day</th>\n",
       "      <th>created_at_time_of_day</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1480304997506113541</td>\n",
       "      <td>2022-01-09 22:26:28</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-01-13 22:11:35</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Providence, Rhode Island, USA</td>\n",
       "      <td>334</td>\n",
       "      <td>703</td>\n",
       "      <td>9</td>\n",
       "      <td>5978</td>\n",
       "      <td>3939</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>AshleyGWinter</td>\n",
       "      <td>thegraindoctor</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>My sister works at the Space Telescope Science...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Night</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>22</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Night</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1480245603233845251</td>\n",
       "      <td>2022-01-09 18:30:28</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-10-29 14:28:41</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Gn-z11</td>\n",
       "      <td>394</td>\n",
       "      <td>757</td>\n",
       "      <td>3</td>\n",
       "      <td>237</td>\n",
       "      <td>544</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>inputhumanname</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>If the new James Webb space telescope was plac...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>14</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1480122742678736899</td>\n",
       "      <td>2022-01-09 10:22:15</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-02-28 08:59:25</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>azizkin</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>could you create more affordable alternatives ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>8</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id          created_at contributors         user_joined  \\\n",
       "0  1480304997506113541 2022-01-09 22:26:28         None 2016-01-13 22:11:35   \n",
       "1  1480245603233845251 2022-01-09 18:30:28         None 2021-10-29 14:28:41   \n",
       "2  1480122742678736899 2022-01-09 10:22:15         None 2008-02-28 08:59:25   \n",
       "\n",
       "          source_text place_country                  user_location  \\\n",
       "0  Twitter for iPhone          <NA>  Providence, Rhode Island, USA   \n",
       "1  Twitter for iPhone          <NA>                         Gn-z11   \n",
       "2     Twitter Web App          <NA>                           None   \n",
       "\n",
       "   user_followers  user_friends  user_listed  user_favourites  user_statuses  \\\n",
       "0             334           703            9             5978           3939   \n",
       "1             394           757            3              237            544   \n",
       "2              94             2            8                1              5   \n",
       "\n",
       "  user_protected user_verified is_quote_status retweeted retweeted_tweet  \\\n",
       "0          False         False           False     False              no   \n",
       "1          False         False           False     False              no   \n",
       "2          False         False           False     False              no   \n",
       "\n",
       "  in_reply_to_screen_name user_screen_name  num_urls_in_tweet_text  num_words  \\\n",
       "0           AshleyGWinter   thegraindoctor                       0         25   \n",
       "1                    None   inputhumanname                       0         33   \n",
       "2                elonmusk          azizkin                       0         20   \n",
       "\n",
       "                                                text  labels  order  hour  \\\n",
       "0  My sister works at the Space Telescope Science...       0      1    22   \n",
       "1  If the new James Webb space telescope was plac...       0      1    18   \n",
       "2  could you create more affordable alternatives ...       1      1    10   \n",
       "\n",
       "   day weekday time_of_day  batch_num split  pred  error  created_at_hour  \\\n",
       "0    9  Sunday       Night          1  test     0  False               22   \n",
       "1    9  Sunday     Evening          1  test     0  False               18   \n",
       "2    9  Sunday     Morning          1  test     1  False               10   \n",
       "\n",
       "  created_at_day  user_joined_hour user_joined_day created_at_time_of_day  \\\n",
       "0         Sunday                22       Wednesday                  Night   \n",
       "1         Sunday                14          Friday                Evening   \n",
       "2         Sunday                 8        Thursday                Morning   \n",
       "\n",
       "  country  \n",
       "0     USA  \n",
       "1   Other  \n",
       "2   Other  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 ms, sys: 5.59 ms, total: 23.3 ms\n",
      "Wall time: 20.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_infer_data_with_preds = pd.read_parquet(infer_file_with_pred)\n",
    "with pd.option_context('display.max_columns', 1000):\n",
    "    display(df_infer_data_with_preds.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06091120-0d80-4edc-b23d-cf0486359c15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1152bac2-d416-4958-8e32-a1684666666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 18.6 ms, total: 1.47 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_infer_data, df_train = [\n",
    "    (\n",
    "        pd.read_excel(\n",
    "            f,\n",
    "            dtype=dtypes_dict,\n",
    "            usecols=list(dtypes_dict)+['created_at', 'user_joined']\n",
    "        ).rename(columns={\"sentiment\": \"labels\"})\n",
    "        # .sort_values(by=['created_at'])\n",
    "        .query(\"~text.str.startswith('RT')\")\n",
    "        .assign(split=st)\n",
    "        .assign(labels=lambda df: df['labels'].isin(needs_support_labels).astype(pd.Int32Dtype()))\n",
    "        .assign(\n",
    "            text=lambda df: (\n",
    "                df[\"text\"]\n",
    "                .str.lstrip()\n",
    "                .str.rstrip()\n",
    "                .str.replace(\"&gt;\", \">\")\n",
    "                .str.replace(\"&lt;\", \"<\")\n",
    "                .str.replace(\"&amp;\", \"&\")\n",
    "            )\n",
    "        )\n",
    "        .assign(created_at_hour=lambda df: df[\"created_at\"].dt.hour)\n",
    "        .assign(\n",
    "            created_at_time_of_day=lambda df: pd.cut(\n",
    "                df[\"created_at_hour\"], bins=b, labels=l, include_lowest=True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    for f, st in zip(proc_files[:-1], ['inference', 'train'])\n",
    "]\n",
    "df_infer_data = df_infer_data.dropna(subset=[\"labels\"]).astype(\n",
    "    {\n",
    "        \"split\": pd.StringDtype(),\n",
    "        \"created_at_hour\": pd.Int32Dtype(),\n",
    "        \"created_at_time_of_day\": pd.StringDtype(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97164c-2033-4cf9-bbc2-59dfd64324c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b283ed2-eaaa-4208-8732-2a38ac460274",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sizes = [{\"train\": len(df_train), \"inference\": len(df_infer_data)}]\n",
    "df_split_sizes = pd.DataFrame.from_records(split_sizes).assign(type=\"raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0609389-9c69-41a3-ad7a-b087fc7d5b7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "764d7421-adb9-4482-9ca5-d49be561747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_nums = df_infer_data[\"batch_num\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34b40ebc-5f83-469b-aea9-0dd842c933ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_current_batch_num = df_infer_data[\"batch_num\"].max()\n",
    "# if df_infer_data[\"batch_num\"].nunique() > 1:\n",
    "#     df_train = pd.concat(\n",
    "#         [df_train, df_infer_data.query(f\"batch_num < {inference_current_batch_num}\")]\n",
    "#     )\n",
    "#     df_infer_data = df_infer_data.query(f\"batch_num == {inference_current_batch_num}\")\n",
    "\n",
    "if len(batch_nums) > 1:\n",
    "    # get all but last batch numbers from test split (to use in training split)\n",
    "    training_batch_nums = batch_nums[:-1]\n",
    "    # get last batch number from test split (to use as current test split)\n",
    "    inference_current_batch_num = batch_nums[-1]\n",
    "\n",
    "    # Slice raw data splits based on batch numbers defined above\n",
    "    df_train = pd.concat(\n",
    "        [df_train, df_infer_data.query(f\"batch_num.isin(@training_batch_nums)\")]\n",
    "    )\n",
    "    df_test = df_infer_data.query(f\"batch_num == {test_current_batch_num}\")\n",
    "else:\n",
    "    inference_current_batch_num = df_infer_data[\"batch_num\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c1cf05-4166-4653-b5dc-bc4c737e8e25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b679c040-6a7e-4b3d-9022-dc2b4c5c694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>inference</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2931</td>\n",
       "      <td>600</td>\n",
       "      <td>raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2775</td>\n",
       "      <td>600</td>\n",
       "      <td>without-duplicates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  inference                type\n",
       "0   2931        600                 raw\n",
       "1   2775        600  without-duplicates"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop_duplicates(subset=[\"text\"])\n",
    "split_sizes_no_dups = [{\"train\": len(df_train), \"inference\": len(df_infer_data)}]\n",
    "df_split_sizes_no_dups = pd.DataFrame.from_records(split_sizes_no_dups).assign(\n",
    "    type=\"without-duplicates\"\n",
    ")\n",
    "df_split_sizes_comp = pd.concat(\n",
    "    [df_split_sizes, df_split_sizes_no_dups], ignore_index=True\n",
    ")\n",
    "df_split_sizes_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a363c39-da32-4feb-9f97-6c355e2b8ea1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba443b7c-c536-4805-a2fd-ab2cef495631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>2021-12-30 17:39:11</td>\n",
       "      <td>2022-01-08 15:14:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inference</td>\n",
       "      <td>2022-01-09 01:18:13</td>\n",
       "      <td>2022-01-10 01:29:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       split                start                  end\n",
       "0      train  2021-12-30 17:39:11  2022-01-08 15:14:33\n",
       "1  inference  2022-01-09 01:18:13  2022-01-10 01:29:01"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split_dates = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\n",
    "            \"split\": split_type,\n",
    "            \"start\": df_nlp_spit[\"created_at\"].min().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"end\": df_nlp_spit[\"created_at\"].max().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "        for df_nlp_spit, split_type in zip(\n",
    "            [df_train, df_infer_data], [\"train\", \"inference\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "df_split_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f80c0-f29b-4908-8a06-42f97314f217",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4819d139-da02-45d1-8064-8e96fc8f6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = df_train[\"created_at\"].max()\n",
    "infer_start = df_infer_data[\"created_at\"].min()\n",
    "assert train_end < infer_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efdfcd-838a-44ef-a108-23400fec5d2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46de5489-7402-40a2-9e12-0ecd447212f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_infer_data.drop(columns=[\"text\", \"split\"]).equals(\n",
    "    df_infer_data_with_preds[list(df_infer_data)].drop(columns=[\"text\", \"split\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963dfac9-0864-4d02-ac4f-124efdb97e76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b5163ef-ca6c-45e5-9f6a-eb40f99a1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [df_train[\"text\"], df_train[\"labels\"]]\n",
    "X_infer_data, y_infer_data = [\n",
    "    df_infer_data_with_preds[\"text\"],\n",
    "    df_infer_data_with_preds[\"labels\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e8021-9ade-43dc-ae88-5d4094826994",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60848b7a-b80f-4633-bfd2-a4c57da18dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"clf\", DummyClassifier(strategy=\"uniform\", random_state=88))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e0025-0644-4221-be18-d53a66c05c8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71186db9-f92c-4000-8edb-5b5c2118e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 669 µs, sys: 195 µs, total: 864 µs\n",
      "Wall time: 826 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bd3ec-1851-43a1-b969-b16bb9f4803b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "503ab96a-0056-4e25-8c81-18e4a9dff552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 ms, sys: 0 ns, total: 1.71 ms\n",
      "Wall time: 1.64 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_infer_pred = (\n",
    "    pd.Series(pipe.predict(X_infer_data), name='label', index=y_infer_data.index)\n",
    "    .astype(pd.Int32Dtype())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2632ba9d-796e-4852-90ab-2304a7c8878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infer_data_with_preds = df_infer_data_with_preds.assign(\n",
    "    pred_naive=y_infer_pred\n",
    ").assign(response_time=lambda df: df[\"num_words\"] * (1 / (135 / 2)) * (60 / 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a6256-1cef-4a5a-9b71-08097b592fe1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12bede35-f0b6-4be4-a69f-1e855cc1e3fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "edd3ab9f-81ff-43da-9201-b7da9a6c15f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f05</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.515</td>\n",
       "      <td>0.516833</td>\n",
       "      <td>0.538858</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.520564</td>\n",
       "      <td>0.529993</td>\n",
       "      <td>0.515681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy  precision  recall        f1       f05  \\\n",
       "0     0.515           0.516833   0.538858   0.515  0.520564  0.529993   \n",
       "\n",
       "         f2  \n",
       "0  0.515681  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>does_not_need_support</th>\n",
       "      <th>needs_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does_not_need_support</td>\n",
       "      <td>185</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>needs_support</td>\n",
       "      <td>112</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Actual  does_not_need_support  needs_support\n",
       "0  does_not_need_support                    185            179\n",
       "1          needs_support                    112            124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>does_not_need_support</th>\n",
       "      <td>0.622896</td>\n",
       "      <td>0.508242</td>\n",
       "      <td>0.559758</td>\n",
       "      <td>364</td>\n",
       "      <td>0.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needs_support</th>\n",
       "      <td>0.409241</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.460111</td>\n",
       "      <td>236</td>\n",
       "      <td>0.393333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score  support      freq\n",
       "does_not_need_support   0.622896  0.508242  0.559758      364  0.606667\n",
       "needs_support           0.409241  0.525424  0.460111      236  0.393333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_dict_inf, df_cm_inf, df_cr_inf = calculate_metrics(\n",
    "    df_infer_data_with_preds[\"labels\"].astype(\"float64\").to_numpy(),\n",
    "    df_infer_data_with_preds[\"pred_naive\"].astype(\"float64\").to_numpy(),\n",
    "    list(label_mapper.values()),\n",
    "    list(label_mapper.keys()),\n",
    "    \"weighted\",\n",
    "    0,\n",
    "    use_sample_weights=False,\n",
    ")\n",
    "df_metrics = pd.DataFrame.from_dict(metrics_dict_inf, orient=\"index\").T\n",
    "df_cr_inf = df_cr_inf.merge(\n",
    "    df_infer_data_with_preds[\"labels\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"freq\")\n",
    "    .reset_index()\n",
    "    .assign(index=lambda df: df[\"index\"].map(id2label))\n",
    "    .set_index(\"index\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "display(df_metrics)\n",
    "display(df_cm_inf)\n",
    "display(df_cr_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea131a53-9e9e-4b6b-b80e-a03e79160896",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5b6e25c0-bc3f-4906-936e-207e53a32dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f05</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.80725</td>\n",
       "      <td>0.812648</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.806673</td>\n",
       "      <td>0.80975</td>\n",
       "      <td>0.805141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy  precision  recall        f1      f05        f2\n",
       "0     0.805            0.80725   0.812648   0.805  0.806673  0.80975  0.805141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>does_not_need_support</th>\n",
       "      <th>needs_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does_not_need_support</td>\n",
       "      <td>290</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>needs_support</td>\n",
       "      <td>43</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Actual  does_not_need_support  needs_support\n",
       "0  does_not_need_support                    290             74\n",
       "1          needs_support                     43            193"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>does_not_need_support</th>\n",
       "      <td>0.870871</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.832138</td>\n",
       "      <td>364</td>\n",
       "      <td>0.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needs_support</th>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.817797</td>\n",
       "      <td>0.767396</td>\n",
       "      <td>236</td>\n",
       "      <td>0.393333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score  support      freq\n",
       "does_not_need_support   0.870871  0.796703  0.832138      364  0.606667\n",
       "needs_support           0.722846  0.817797  0.767396      236  0.393333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_dict_inf, df_cm_inf, df_cr_inf = calculate_metrics(\n",
    "    df_infer_data_with_preds[\"labels\"].astype(\"float64\").to_numpy(),\n",
    "    df_infer_data_with_preds[\"pred\"].astype(\"float64\").to_numpy(),\n",
    "    list(label_mapper.values()),\n",
    "    list(label_mapper.keys()),\n",
    "    \"weighted\",\n",
    "    0,\n",
    "    use_sample_weights=False,\n",
    ")\n",
    "df_metrics = pd.DataFrame.from_dict(metrics_dict_inf, orient=\"index\").T\n",
    "df_cr_inf = df_cr_inf.merge(\n",
    "    df_infer_data_with_preds[\"labels\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"freq\")\n",
    "    .reset_index()\n",
    "    .assign(index=lambda df: df[\"index\"].map(id2label))\n",
    "    .set_index(\"index\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "display(df_metrics)\n",
    "display(df_cm_inf)\n",
    "display(df_cr_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a8e4b-3cb7-4ce7-bc21-aa54480130e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "af455d1a-0633-48e7-8e5f-2cc2700114e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>labels</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_naive</th>\n",
       "      <th>num_words</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1480304997506113541</td>\n",
       "      <td>2022-01-09 22:26:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1480245603233845251</td>\n",
       "      <td>2022-01-09 18:30:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>29.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1480122742678736899</td>\n",
       "      <td>2022-01-09 10:22:15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>17.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id          created_at  labels  pred  pred_naive  \\\n",
       "0  1480304997506113541 2022-01-09 22:26:28       0     0           0   \n",
       "1  1480245603233845251 2022-01-09 18:30:28       0     0           0   \n",
       "2  1480122742678736899 2022-01-09 10:22:15       1     1           1   \n",
       "\n",
       "   num_words  response_time  \n",
       "0         25      22.222222  \n",
       "1         33      29.333333  \n",
       "2         20      17.777778  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_infer_data_with_preds[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"created_at\",\n",
    "            \"labels\",\n",
    "            \"pred\",\n",
    "            \"pred_naive\",\n",
    "            \"num_words\",\n",
    "            \"response_time\",\n",
    "        ]\n",
    "    ].head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633d0cf-b362-44dd-b665-9e1b73d1bfda",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e506c0d-5c2d-4f88-941c-4f64b60fbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missed = df_infer_data_with_preds.query(\"(labels == 1) & (pred == 0)\")\n",
    "df_wasted = df_infer_data_with_preds.query(\"(labels == 0) & (pred == 1)\")\n",
    "df_missed_naive = df_infer_data_with_preds.query(\"(labels == 1) & (pred_naive == 0)\")\n",
    "df_wasted_naive = df_infer_data_with_preds.query(\"(labels == 0) & (pred_naive == 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6ff9b3e8-4c21-4450-bffa-6c267a4ff20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batch_num</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_missed</th>\n",
       "      <td>13.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_missed_naive</th>\n",
       "      <td>45.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_num</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_wasted</th>\n",
       "      <td>29.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_wasted_naive</th>\n",
       "      <td>59.422222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_number_tweets</th>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_needs_support</th>\n",
       "      <td>236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_reduction_in_time_wasted</th>\n",
       "      <td>50.261780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_reduction_in_time_missed</th>\n",
       "      <td>70.825147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_missed</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_missed_naive</th>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_unnecessarily_read</th>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_unnecessarily_read_naive</th>\n",
       "      <td>179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frac_tweets_unnecessarily_read</th>\n",
       "      <td>0.123333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frac_tweets_missed</th>\n",
       "      <td>0.071667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frac_tweets_unnecessarily_read_naive</th>\n",
       "      <td>0.298333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frac_tweets_missed_naive</th>\n",
       "      <td>0.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_time_true</th>\n",
       "      <td>93.570370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_time_pred</th>\n",
       "      <td>109.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_time_pred_naive</th>\n",
       "      <td>107.748148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "batch_num                               1.000000\n",
       "time_missed                            13.200000\n",
       "time_missed_naive                      45.244444\n",
       "batch_num                               1.000000\n",
       "time_wasted                            29.555556\n",
       "time_wasted_naive                      59.422222\n",
       "total_number_tweets                   600.000000\n",
       "num_needs_support                     236.000000\n",
       "pct_reduction_in_time_wasted           50.261780\n",
       "pct_reduction_in_time_missed           70.825147\n",
       "num_tweets_missed                      43.000000\n",
       "num_tweets_missed_naive               112.000000\n",
       "num_tweets_unnecessarily_read          74.000000\n",
       "num_tweets_unnecessarily_read_naive   179.000000\n",
       "frac_tweets_unnecessarily_read          0.123333\n",
       "frac_tweets_missed                      0.071667\n",
       "frac_tweets_unnecessarily_read_naive    0.298333\n",
       "frac_tweets_missed_naive                0.186667\n",
       "response_time_true                     93.570370\n",
       "response_time_pred                    109.925926\n",
       "response_time_pred_naive              107.748148"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_missed = dict(\n",
    "    batch_num=inference_current_batch_num,\n",
    "    time_missed=df_missed[\"response_time\"].sum() / 60,\n",
    "    time_missed_naive=df_missed_naive[\"response_time\"].sum() / 60,\n",
    ")\n",
    "dict_wasted = dict(\n",
    "    batch_num=inference_current_batch_num,\n",
    "    time_wasted=df_wasted[\"response_time\"].sum() / 60,\n",
    "    time_wasted_naive=df_wasted_naive[\"response_time\"].sum() / 60,\n",
    ")\n",
    "df_summary = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame.from_dict(dict_missed, orient=\"index\"),\n",
    "        pd.DataFrame.from_dict(dict_wasted, orient=\"index\"),\n",
    "    ]\n",
    ")\n",
    "df_summary.T.assign(total_number_tweets=len(df_infer_data_with_preds)).assign(\n",
    "    num_needs_support=len(df_infer_data_with_preds.query(\"labels == 1\"))\n",
    ").assign(\n",
    "    pct_reduction_in_time_wasted=lambda df: 100\n",
    "    * (df[\"time_wasted_naive\"] - df[\"time_wasted\"])\n",
    "    / df[\"time_wasted_naive\"]\n",
    ").assign(\n",
    "    pct_reduction_in_time_missed=lambda df: 100\n",
    "    * (df[\"time_missed_naive\"] - df[\"time_missed\"])\n",
    "    / df[\"time_missed_naive\"]\n",
    ").assign(\n",
    "    num_tweets_missed=len(df_missed)\n",
    ").assign(\n",
    "    num_tweets_missed_naive=len(df_missed_naive)\n",
    ").assign(\n",
    "    num_tweets_unnecessarily_read=len(df_wasted)\n",
    ").assign(\n",
    "    num_tweets_unnecessarily_read_naive=len(df_wasted_naive)\n",
    ").assign(\n",
    "    frac_tweets_unnecessarily_read=lambda df: df[\"num_tweets_unnecessarily_read\"]\n",
    "    / len(df_infer_data_with_preds)\n",
    ").assign(\n",
    "    frac_tweets_missed=lambda df: df[\"num_tweets_missed\"]\n",
    "    / len(df_infer_data_with_preds)\n",
    ").assign(\n",
    "    frac_tweets_unnecessarily_read_naive=lambda df: df[\n",
    "        \"num_tweets_unnecessarily_read_naive\"\n",
    "    ]\n",
    "    / len(df_infer_data_with_preds)\n",
    ").assign(\n",
    "    frac_tweets_missed_naive=lambda df: df[\"num_tweets_missed_naive\"]\n",
    "    / len(df_infer_data_with_preds)\n",
    ").assign(\n",
    "    response_time_true=df_infer_data_with_preds.query(\"labels == 1\")[\n",
    "        \"response_time\"\n",
    "    ].sum()\n",
    "    / 60\n",
    ").assign(\n",
    "    response_time_pred=df_infer_data_with_preds.query(\"pred == 1\")[\n",
    "        \"response_time\"\n",
    "    ].sum()\n",
    "    / 60\n",
    ").assign(\n",
    "    response_time_pred_naive=df_infer_data_with_preds.query(\"pred_naive == 1\")[\n",
    "        \"response_time\"\n",
    "    ].sum()\n",
    "    / 60\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f392ca46-9e7d-4338-8b9a-b76c1cccaf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemakertestwillz3s/datasets/twitter/kinesis-demo/processed/nlp_splits/metrics__inference_starts_20220110_000000__batch_1__with_preds.parquet.gzip'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = f\"{path_to_folder[1:]}processed/nlp_splits/metrics__inference_starts_20220110_000000__batch_1__with_preds.parquet.gzip\"\n",
    "fpath = f\"s3://{s3_bucket_name}/{prefix}\"\n",
    "fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0c2ec728-7d9f-4de0-a2a1-6ca04c30f1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batch_num</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_number_tweets</th>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_needs_support</th>\n",
       "      <td>303</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frac_needs_support</th>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.393333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_frac_needs_support</th>\n",
       "      <td>0.505</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_needed_true</th>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_needed_pred</th>\n",
       "      <td>303</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_time_pred</th>\n",
       "      <td>107.748146</td>\n",
       "      <td>109.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_time_true</th>\n",
       "      <td>93.570374</td>\n",
       "      <td>93.570374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_type</th>\n",
       "      <td>naive</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_needs_support</th>\n",
       "      <td>0.460111</td>\n",
       "      <td>0.767396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.520564</td>\n",
       "      <td>0.806673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f05</th>\n",
       "      <td>0.529993</td>\n",
       "      <td>0.80975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>0.515681</td>\n",
       "      <td>0.805141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_unnecessarily_read</th>\n",
       "      <td>179</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tweets_missed</th>\n",
       "      <td>112</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frac_tweets_unnecessarily_read</th>\n",
       "      <td>0.298333</td>\n",
       "      <td>0.123333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frac_tweets_missed</th>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.071667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_wasted</th>\n",
       "      <td>59.422222</td>\n",
       "      <td>29.555555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_missed</th>\n",
       "      <td>45.244446</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_reduction_in_time_wasted</th>\n",
       "      <td>50.26178</td>\n",
       "      <td>50.26178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_reduction_in_time_missed</th>\n",
       "      <td>70.82515</td>\n",
       "      <td>70.82515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0           1\n",
       "batch_num                                1           1\n",
       "total_number_tweets                    600         600\n",
       "num_needs_support                      303         267\n",
       "frac_needs_support                0.393333    0.393333\n",
       "pred_frac_needs_support              0.505       0.445\n",
       "num_tweets_needed_true                 236         236\n",
       "num_tweets_needed_pred                 303         267\n",
       "response_time_pred              107.748146  109.925926\n",
       "response_time_true               93.570374   93.570374\n",
       "pred_type                            naive          ML\n",
       "f1_needs_support                  0.460111    0.767396\n",
       "f1                                0.520564    0.806673\n",
       "f05                               0.529993     0.80975\n",
       "f2                                0.515681    0.805141\n",
       "num_tweets_unnecessarily_read          179          74\n",
       "num_tweets_missed                      112          43\n",
       "frac_tweets_unnecessarily_read    0.298333    0.123333\n",
       "frac_tweets_missed                0.186667    0.071667\n",
       "time_wasted                      59.422222   29.555555\n",
       "time_missed                      45.244446        13.2\n",
       "pct_reduction_in_time_wasted      50.26178    50.26178\n",
       "pct_reduction_in_time_missed      70.82515    70.82515"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(fpath).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa562a9a-e79b-451d-8296-929a306719f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ded74-a2ae-4e5f-80c5-3d75eedbde12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa2b0d8-a15a-43ec-af02-a4e8e0ee503c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94fb9aa-c991-4da5-b838-1b1f8bc918c2",
   "metadata": {},
   "source": [
    "<span style=\"float:left;\">\n",
    "    <a href=\"./3-combine-data/notebooks/3_combine_data.ipynb\"><< 3 - Combine Hourly Streamed Tweets</a>\n",
    "</span>\n",
    "\n",
    "<span style=\"float:right;\">\n",
    "    <a href=\"./5-process-data/notebooks/5_process_data.ipynb\">5 - Data Processing >></a>\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assess",
   "language": "python",
   "name": "assess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
