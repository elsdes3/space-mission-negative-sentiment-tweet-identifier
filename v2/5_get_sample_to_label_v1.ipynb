{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444aaf44-4153-4de4-8240-eb64e8d9769e",
   "metadata": {},
   "source": [
    "# Create Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb485cc1-fb1b-4711-9c0f-15bd2895d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black==22.6.0\n",
      "boto3==1.24.56\n",
      "dask==2022.8.0\n",
      "dask-ml==2022.5.27\n",
      "distributed==2022.8.0\n",
      "nb-black==1.0.7\n",
      "pandas==1.4.3\n",
      "s3fs==0.4.2\n",
      "scikit-learn==1.1.2\n",
      "ipykernel                 6.15.1             pyh210e3f2_0    conda-forge\n",
      "CPU times: user 24.9 ms, sys: 22.8 ms, total: 47.6 ms\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip3 freeze | grep -E 'boto3|s3fs|scikit-learn|distributed|dask==|dask-m|black==|jupyter-server|pandas'\n",
    "!conda list -n spark | grep -E 'ipykernel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5ede44-eaa0-4209-9652-e85ae11c2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e1ff41-c5cc-4b80-8fb6-5e970e8b8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "\n",
    "import boto3\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47d23f-5aca-4157-8f66-667e4fbcdf38",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358b6aa-36c9-4838-9713-17b8ee277dd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Objective\n",
    "This notebook will split the processed data into training, validation and test splits that can be used to train a machine learning model for twitter sentiment classification.\n",
    "\n",
    "### ML Model Development\n",
    "A random sample of the training split will be further divided into three smaller splits in order to support training a NLP (transformers) model to predict sentiment. This NLP model will be used to label the processed tweets data with sentiment. The NLP model will be used to label the data (i.e. to extract the sentiment) used during ML model development. The ML model will be trained using this labeled data and then deployed.\n",
    "\n",
    "### ML Model Usage in Production\n",
    "In production, the deployed ML model will be used to predict sentiment of incoming tweets on-demand. These predictions will be served to customers.\n",
    "\n",
    "### ML Model Drift Monitoring\n",
    "After the same fraction of inference predictions have been made as the size of the validation of test splits used during ML model development, the following will be performed\n",
    "- all tweets predicted during inference are labeled\n",
    "  - manually\n",
    "  - using the **previously trained NLP model**\n",
    "- deployed ML model predictions, made during inference, will be scored against these labels (previous bullet point) in order to determine if ML model performance has\n",
    "  - drifted (the ML training pipeline will be triggered)\n",
    "    - scores are not within some threshold of the scores on the test split during ML model development\n",
    "    - predictions made by the **previously trained NLP model** will be served to the customer\n",
    "      - the other option here is to serve the same (poorly scoring) predictions made by the ML model to the customers\n",
    "    - updated training, validation and testing splits will be created using *all available data*\n",
    "    - a new ML model will be trained using *all available data* and will then be deployed to production\n",
    "  - not drifted\n",
    "    - scores are within some threshold of the scores on the test split during ML model development\n",
    "    - the currently used ML model will continue to serve inference\n",
    "\n",
    "*All available data* here will include\n",
    "- the original data used for ML model development\n",
    "- the new data used to make inference with the originally trained ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da003d84-d869-412e-b32e-87e95d72c710",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0114977-12b2-4d51-9b43-2182f5367d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_folder = \"/datasets/twitter/kinesis-demo/\"\n",
    "\n",
    "# processed data\n",
    "processed_data_dir = \"data/processed\"\n",
    "processed_file_name = \"processed_text\"\n",
    "\n",
    "# train-test split\n",
    "test_split_frac = 0.125\n",
    "\n",
    "# sampling data\n",
    "num_sampled_tweets = 10_000\n",
    "sampled_fname = \"sampled_data.csv.zip\"\n",
    "\n",
    "# inference\n",
    "inference_start_date = \"2022-01-10 00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44af9bd9-bb26-402a-a106-3d37bdc81f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_name = os.getenv(\"AWS_S3_BUCKET_NAME\")\n",
    "session = boto3.Session(profile_name=\"default\")\n",
    "s3_client = session.client(\"s3\")\n",
    "\n",
    "dtypes_dict = {\n",
    "    \"id\": pd.StringDtype(),\n",
    "    \"geo\": pd.StringDtype(),\n",
    "    \"coordinates\": pd.StringDtype(),\n",
    "    \"place\": pd.StringDtype(),\n",
    "    \"contributors\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"is_quote_status\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"quote_count\": pd.Int32Dtype(),\n",
    "    \"reply_count\": pd.Int32Dtype(),\n",
    "    \"retweet_count\": pd.Int32Dtype(),\n",
    "    \"favorite_count\": pd.Int32Dtype(),\n",
    "    \"favorited\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"retweeted\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"source\": pd.StringDtype(),\n",
    "    \"in_reply_to_user_id\": pd.StringDtype(),\n",
    "    \"in_reply_to_screen_name\": pd.StringDtype(),\n",
    "    \"source_text\": pd.StringDtype(),\n",
    "    \"place_id\": pd.StringDtype(),\n",
    "    \"place_url\": pd.StringDtype(),\n",
    "    \"place_place_type\": pd.StringDtype(),\n",
    "    \"place_name\": pd.StringDtype(),\n",
    "    \"place_full_name\": pd.StringDtype(),\n",
    "    \"place_country_code\": pd.StringDtype(),\n",
    "    \"place_country\": pd.StringDtype(),\n",
    "    \"place_bounding_box_type\": pd.StringDtype(),\n",
    "    \"place_bounding_box_coordinates\": pd.StringDtype(),\n",
    "    \"place_attributes\": pd.StringDtype(),\n",
    "    \"coords_type\": pd.StringDtype(),\n",
    "    \"coords_lon\": pd.StringDtype(),\n",
    "    \"coords_lat\": pd.StringDtype(),\n",
    "    \"geo_type\": pd.StringDtype(),\n",
    "    \"geo_lon\": pd.StringDtype(),\n",
    "    \"geo_lat\": pd.StringDtype(),\n",
    "    \"user_name\": pd.StringDtype(),\n",
    "    \"user_screen_name\": pd.StringDtype(),\n",
    "    \"user_followers\": pd.Int32Dtype(),\n",
    "    \"user_friends\": pd.Int32Dtype(),\n",
    "    \"user_listed\": pd.Int32Dtype(),\n",
    "    \"user_favourites\": pd.Int32Dtype(),\n",
    "    \"user_statuses\": pd.Int32Dtype(),\n",
    "    \"user_protected\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"user_verified\": pd.StringDtype(),  # pd.BooleanDtype(),\n",
    "    \"user_contributors_enabled\": pd.StringDtype(),\n",
    "    \"user_location\": pd.StringDtype(),\n",
    "    \"retweeted_tweet\": pd.StringDtype(),\n",
    "    \"tweet_text_urls\": pd.StringDtype(),\n",
    "    \"tweet_text_hashtags\": pd.StringDtype(),\n",
    "    \"tweet_text_usernames\": pd.StringDtype(),\n",
    "    \"num_urls_in_tweet_text\": pd.Int32Dtype(),\n",
    "    \"num_users_in_tweet_text\": pd.Int32Dtype(),\n",
    "    \"num_hashtags_in_tweet_text\": pd.Int32Dtype(),\n",
    "    \"text\": pd.StringDtype(),\n",
    "    \"contains_wanted_text\": pd.BooleanDtype(),\n",
    "    \"contains_wanted_text_case_sensitive\": pd.BooleanDtype(),\n",
    "    \"contains_multi_word_wanted_text\": pd.BooleanDtype(),\n",
    "    \"contains_crypto_terms\": pd.BooleanDtype(),\n",
    "    \"contains_religious_terms\": pd.BooleanDtype(),\n",
    "    \"contains_inappropriate_terms\": pd.BooleanDtype(),\n",
    "    \"contains_video_games_terms\": pd.BooleanDtype(),\n",
    "    \"contains_misc_unwanted_terms\": pd.BooleanDtype(),\n",
    "    \"contains_non_english_terms\": pd.BooleanDtype(),\n",
    "    \"text_trimmed\": pd.StringDtype(),\n",
    "    \"text_stripped\": pd.StringDtype(),\n",
    "    \"text_processed\": pd.StringDtype(),\n",
    "    \"words\": pd.StringDtype(),\n",
    "    \"num_words\": pd.Int32Dtype(),\n",
    "}\n",
    "\n",
    "proc_text_zip_fname = f\"{processed_file_name}.zip\"\n",
    "\n",
    "val_split_frac = test_split_frac / (1 - test_split_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3995b943-2fec-4c28-b11d-94e448757b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_cols(df_cols, cols_to_use):\n",
    "    \"\"\"Highlight a list of columns in a DataFrame.\"\"\"\n",
    "    # copy df to new - original data is not changed\n",
    "    df = df_cols[cols_to_use].copy()\n",
    "    # select all values to yellow color\n",
    "    df.loc[:, :] = \"background-color: yellow\"\n",
    "    # return color df\n",
    "    return df\n",
    "\n",
    "\n",
    "def download_file_from_s3(\n",
    "    s3_bucket_name: str,\n",
    "    path_to_folder: str,\n",
    "    data_dir: str,\n",
    "    fname: str,\n",
    "    aws_region: str,\n",
    "    prefix: str,\n",
    ") -> None:\n",
    "    \"\"\"Download file from .\"\"\"\n",
    "    dest_filepath = os.path.join(data_dir, fname)\n",
    "    s3_filepath_key = s3_client.list_objects_v2(\n",
    "        Bucket=s3_bucket_name,\n",
    "        Delimiter=\"/\",\n",
    "        Prefix=prefix,\n",
    "    )[\"Contents\"][0][\"Key\"]\n",
    "    start = datetime.now()\n",
    "    print(\n",
    "        f\"Started downloading processed data zip file from {s3_filepath_key} to \"\n",
    "        f\"{dest_filepath} at {start.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}...\"\n",
    "    )\n",
    "    s3 = boto3.resource(\"s3\", region_name=aws_region)\n",
    "    s3.meta.client.download_file(\n",
    "        s3_bucket_name,\n",
    "        s3_filepath_key,\n",
    "        dest_filepath,\n",
    "    )\n",
    "    duration = (datetime.now() - start).total_seconds()\n",
    "    print(f\"Done downloading in {duration:.3f} seconds.\")\n",
    "\n",
    "\n",
    "def extract_zip_file(dest_filepath: str, data_dir: str) -> None:\n",
    "    \"\"\".\"\"\"\n",
    "    start = datetime.now()\n",
    "    print(\n",
    "        \"Started extracting filtered data parquet files from \"\n",
    "        f\"processed data zip file to {data_dir} at \"\n",
    "        f\"{start.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}...\"\n",
    "    )\n",
    "    zip_ref = zipfile.ZipFile(dest_filepath)\n",
    "    zip_ref.extractall(data_dir)\n",
    "    zip_ref.close()\n",
    "    duration = (datetime.now() - start).total_seconds()\n",
    "    print(f\"Done extracting in {duration:.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c850312-4502-4ee7-8f94-9bfb7a1322f2",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07be3d1-0e0c-4df1-ad57-4cb1bf9cbbba",
   "metadata": {},
   "source": [
    "We will start by downloaded the processed and filtered `.zip` file from S3 and extracting all the contained `.parquet` files into a `.parquet.gzip` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6e6661-fc45-421e-8a00-0ad4961a6734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 ms, sys: 0 ns, total: 1.16 ms\n",
      "Wall time: 849 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.exists(os.path.join(processed_data_dir, proc_text_zip_fname)):\n",
    "    download_file_from_s3(\n",
    "        s3_bucket_name,\n",
    "        path_to_folder,\n",
    "        processed_data_dir,\n",
    "        proc_text_zip_fname,\n",
    "        session.region_name,\n",
    "        f\"{path_to_folder[1:]}processed/{os.path.splitext(proc_text_zip_fname)[0]}\",\n",
    "    )\n",
    "    extract_zip_file(\n",
    "        os.path.join(processed_data_dir, proc_text_zip_fname),\n",
    "        f\"{processed_data_dir}/{os.path.splitext(proc_text_zip_fname)[0]}.parquet.gzip\",\n",
    "    )\n",
    "proc_files = glob(f\"{processed_data_dir}/*.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa7314-4451-4f05-afb4-53b57b700578",
   "metadata": {},
   "source": [
    "Use Dask to load the `.parquet.gzip` file (consisting of multiple `.parquet` files) into a single Dask DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd70cd79-4059-4e9d-bfa0-308b7aedce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geo</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>contributors</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>contains_religious_terms</th>\n",
       "      <th>contains_inappropriate_terms</th>\n",
       "      <th>contains_video_games_terms</th>\n",
       "      <th>contains_misc_unwanted_terms</th>\n",
       "      <th>contains_non_english_terms</th>\n",
       "      <th>text_stripped</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_trimmed</th>\n",
       "      <th>words</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1479845397946380290</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LIVE from mission control: experts give real-time updates as the telescope's golden honeycomb-like mirror takes its final shape in space. This marks the end of an unprecedented 14-day deployment process! Use for questions.</td>\n",
       "      <td>live from mission control  experts give real time updates as the telescope s golden honeycomb like mirror takes its final shape in space  this marks the end of an unprecedented    day deployment process  use for questions</td>\n",
       "      <td>LIVE from mission control:  experts give real-time updates as the telescope's golden honeycomb-like mirror takes its final shape in space. This marks the end of an unprecedented 14-day deployment process! Use  for questions.</td>\n",
       "      <td>[LIVE, from, mission, control:, experts, give, real-time, updates, as, the, telescope's, golden, honeycomb-like, mirror, takes, its, final, shape, in, space., This, marks, the, end, of, an, unprecedented, 14-day, deployment, process!, Use, for, questions.]</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1479845401289179139</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>This was taken when we covered the NASA Night Launch! It was a WoW Experience! CapeCanaveral Florida travel luxurytravel adventuretravel</td>\n",
       "      <td>this was taken when we covered the nasa night launch  it was a wow experience  capecanaveral florida travel luxurytravel adventuretravel</td>\n",
       "      <td>This was taken when we  covered the NASA Night Launch! It was a WoW Experience! CapeCanaveral Florida travel luxurytravel adventuretravel</td>\n",
       "      <td>[This, was, taken, when, we, covered, the, NASA, Night, Launch!, It, was, a, WoW, Experience!, CapeCanaveral, Florida, travel, luxurytravel, adventuretravel]</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1479845404762152969</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nearly halfway through its flight to L2 (vs time required), will fully deploy its primary mirror hopefully marking the end of the most complex space telescope deployment in history. Watch live coverage from mission control at 14:00 UTC:</td>\n",
       "      <td>nearly halfway through its flight to l   vs time required   will fully deploy its primary mirror hopefully marking the end of the most complex space telescope deployment in history  watch live coverage from mission control at       utc</td>\n",
       "      <td>Nearly halfway through its flight to L2 (vs time required),  will fully deploy its primary mirror  hopefully marking the end of the most complex space telescope deployment in history. Watch live coverage from mission control at 14:00 UTC:</td>\n",
       "      <td>[Nearly, halfway, through, its, flight, to, L2, (vs, time, required),, will, fully, deploy, its, primary, mirror, hopefully, marking, the, end, of, the, most, complex, space, telescope, deployment, in, history., Watch, live, coverage, from, mission, control, at, 14:00, UTC:]</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1479845407085629445</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Time and life of Stephen Hawking | News18 Tamil Nadu via</td>\n",
       "      <td>time and life of stephen hawking   news   tamil nadu via</td>\n",
       "      <td>Time and life of Stephen Hawking  | News18 Tamil Nadu  via</td>\n",
       "      <td>[Time, and, life, of, Stephen, Hawking, |, News18, Tamil, Nadu, via]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1479845409014964230</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>\"The scientists at National Aeronautics and Space Administration (NASA) have acknowledged that Sanskrit is the most scientific language</td>\n",
       "      <td>the scientists at national aeronautics and space administration  nasa  have acknowledged that sanskrit is the most scientific language</td>\n",
       "      <td>\"The scientists at National Aeronautics and Space Administration (NASA) have acknowledged that Sanskrit is the most scientific language</td>\n",
       "      <td>[\"The, scientists, at, National, Aeronautics, and, Space, Administration, (NASA), have, acknowledged, that Sanskrit, is, the, most, scientific, language]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   geo coordinates place contributors is_quote_status  \\\n",
       "0  1479845397946380290  None        None  None         None           False   \n",
       "1  1479845401289179139  None        None  None         None           False   \n",
       "2  1479845404762152969  None        None  None         None           False   \n",
       "3  1479845407085629445  None        None  None         None           False   \n",
       "4  1479845409014964230  None        None  None         None           False   \n",
       "\n",
       "   quote_count  reply_count  retweet_count  favorite_count  ...  \\\n",
       "0            0            0              0               0  ...   \n",
       "1            0            0              0               0  ...   \n",
       "2            0            0              0               0  ...   \n",
       "3            0            0              0               0  ...   \n",
       "4            0            0              0               0  ...   \n",
       "\n",
       "  contains_religious_terms contains_inappropriate_terms  \\\n",
       "0                    False                        False   \n",
       "1                    False                        False   \n",
       "2                    False                        False   \n",
       "3                    False                        False   \n",
       "4                    False                        False   \n",
       "\n",
       "  contains_video_games_terms contains_misc_unwanted_terms  \\\n",
       "0                      False                        False   \n",
       "1                      False                        False   \n",
       "2                      False                        False   \n",
       "3                      False                        False   \n",
       "4                      False                        False   \n",
       "\n",
       "  contains_non_english_terms  \\\n",
       "0                      False   \n",
       "1                      False   \n",
       "2                      False   \n",
       "3                      False   \n",
       "4                      False   \n",
       "\n",
       "                                                                                                                                                                                                                                  text_stripped  \\\n",
       "0                LIVE from mission control: experts give real-time updates as the telescope's golden honeycomb-like mirror takes its final shape in space. This marks the end of an unprecedented 14-day deployment process! Use for questions.   \n",
       "1                                                                                                      This was taken when we covered the NASA Night Launch! It was a WoW Experience! CapeCanaveral Florida travel luxurytravel adventuretravel   \n",
       "2  Nearly halfway through its flight to L2 (vs time required), will fully deploy its primary mirror hopefully marking the end of the most complex space telescope deployment in history. Watch live coverage from mission control at 14:00 UTC:   \n",
       "3                                                                                                                                                                                      Time and life of Stephen Hawking | News18 Tamil Nadu via   \n",
       "4                                                                                                       \"The scientists at National Aeronautics and Space Administration (NASA) have acknowledged that Sanskrit is the most scientific language   \n",
       "\n",
       "                                                                                                                                                                                                                                 text_processed  \\\n",
       "0                live from mission control  experts give real time updates as the telescope s golden honeycomb like mirror takes its final shape in space  this marks the end of an unprecedented    day deployment process  use for questions    \n",
       "1                                                                                                      this was taken when we covered the nasa night launch  it was a wow experience  capecanaveral florida travel luxurytravel adventuretravel   \n",
       "2  nearly halfway through its flight to l   vs time required   will fully deploy its primary mirror hopefully marking the end of the most complex space telescope deployment in history  watch live coverage from mission control at       utc    \n",
       "3                                                                                                                                                                                      time and life of stephen hawking   news   tamil nadu via   \n",
       "4                                                                                                        the scientists at national aeronautics and space administration  nasa  have acknowledged that sanskrit is the most scientific language   \n",
       "\n",
       "                                                                                                                                                                                                                                     text_trimmed  \\\n",
       "0                LIVE from mission control:  experts give real-time updates as the telescope's golden honeycomb-like mirror takes its final shape in space. This marks the end of an unprecedented 14-day deployment process! Use  for questions.   \n",
       "1                                                                                                       This was taken when we  covered the NASA Night Launch! It was a WoW Experience! CapeCanaveral Florida travel luxurytravel adventuretravel   \n",
       "2  Nearly halfway through its flight to L2 (vs time required),  will fully deploy its primary mirror  hopefully marking the end of the most complex space telescope deployment in history. Watch live coverage from mission control at 14:00 UTC:   \n",
       "3                                                                                                                                                                                      Time and life of Stephen Hawking  | News18 Tamil Nadu  via   \n",
       "4                                                                                                         \"The scientists at National Aeronautics and Space Administration (NASA) have acknowledged that Sanskrit is the most scientific language   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                 words  \\\n",
       "0                     [LIVE, from, mission, control:, experts, give, real-time, updates, as, the, telescope's, golden, honeycomb-like, mirror, takes, its, final, shape, in, space., This, marks, the, end, of, an, unprecedented, 14-day, deployment, process!, Use, for, questions.]   \n",
       "1                                                                                                                        [This, was, taken, when, we, covered, the, NASA, Night, Launch!, It, was, a, WoW, Experience!, CapeCanaveral, Florida, travel, luxurytravel, adventuretravel]   \n",
       "2  [Nearly, halfway, through, its, flight, to, L2, (vs, time, required),, will, fully, deploy, its, primary, mirror, hopefully, marking, the, end, of, the, most, complex, space, telescope, deployment, in, history., Watch, live, coverage, from, mission, control, at, 14:00, UTC:]   \n",
       "3                                                                                                                                                                                                                 [Time, and, life, of, Stephen, Hawking, |, News18, Tamil, Nadu, via]   \n",
       "4                                                                                                                            [\"The, scientists, at, National, Aeronautics, and, Space, Administration, (NASA), have, acknowledged, that Sanskrit, is, the, most, scientific, language]   \n",
       "\n",
       "  num_words  \n",
       "0        33  \n",
       "1        20  \n",
       "2        38  \n",
       "3        11  \n",
       "4        17  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinates</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contributors</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_stripped</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_processed</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_trimmed</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_words</th>\n",
       "      <td>Int32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dtype\n",
       "id              string\n",
       "geo             string\n",
       "coordinates     string\n",
       "place           string\n",
       "contributors    string\n",
       "...                ...\n",
       "text_stripped   string\n",
       "text_processed  string\n",
       "text_trimmed    string\n",
       "words           string\n",
       "num_words        Int32\n",
       "\n",
       "[67 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 710 ms, sys: 142 ms, total: 852 ms\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ddf = dd.read_parquet(proc_files).astype(dtypes_dict)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(ddf.head())\n",
    "display(ddf.dtypes.rename(\"dtype\").to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54568dc-6b45-472e-89a8-14ee92d5e20d",
   "metadata": {},
   "source": [
    "## Split Data and Create Sample for Training NLP Labeling (Transformer) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1522cc1-7e73-4a3d-a1d6-51523d696eef",
   "metadata": {},
   "source": [
    "### Create Data Splits for ML Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e7f61-a000-42ed-832f-1c48e3e4adeb",
   "metadata": {},
   "source": [
    "Create non-randomized training, validation and test splits from data pre-dating first inference `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bea2073-ad49-4e3c-93bf-490e1bb070d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 129 ms, sys: 246 µs, total: 129 ms\n",
      "Wall time: 160 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_all = ddf[ddf[\"created_at\"] < inference_start_date]\n",
    "df_train_val, df_test = train_test_split(\n",
    "    df_all, test_size=test_split_frac, random_state=88, shuffle=True\n",
    ")\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train_val, test_size=val_split_frac, random_state=88, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e68705-29cd-436a-b6ae-fc44a3e24c8e",
   "metadata": {},
   "source": [
    "Get split lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "533c8a20-5207-4a45-8431-010804ba48a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 1.86 s, total: 16 s\n",
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_len</th>\n",
       "      <th>val_len</th>\n",
       "      <th>test_len</th>\n",
       "      <th>total</th>\n",
       "      <th>desired_val_frac</th>\n",
       "      <th>desired_test_frac</th>\n",
       "      <th>val_frac</th>\n",
       "      <th>test_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170037</td>\n",
       "      <td>28361</td>\n",
       "      <td>28249</td>\n",
       "      <td>226647</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125133</td>\n",
       "      <td>0.124639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_len  val_len  test_len   total  desired_val_frac  desired_test_frac  \\\n",
       "0     170037    28361     28249  226647          0.142857              0.125   \n",
       "\n",
       "   val_frac  test_frac  \n",
       "0  0.125133   0.124639  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_rand_dates = (\n",
    "    pd.DataFrame([len(df_train)], columns=['train_len'])\n",
    "    .assign(val_len=len(df_val))\n",
    "    .assign(test_len=len(df_test))\n",
    "    .assign(\n",
    "        total=lambda df: df[\"train_len\"]\n",
    "        + df[\"val_len\"]\n",
    "        + df[\"test_len\"]\n",
    "    )\n",
    "    .assign(desired_val_frac=val_split_frac)\n",
    "    .assign(desired_test_frac=test_split_frac)\n",
    "    .assign(val_frac=lambda df: df[\"val_len\"] / df[\"total\"])\n",
    "    .assign(test_frac=lambda df: df[\"test_len\"] / df[\"total\"])\n",
    ")\n",
    "df_rand_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d9822-cbdb-488e-846a-fd6d4e29b7bc",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The columns ending in `_frac` are the fraction of rows in the\n",
    "   - validation split\n",
    "   - testing split\n",
    "\n",
    "   relative to the total number of rows across the combination of\n",
    "   - training split\n",
    "   - validation split\n",
    "   - test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae021ca0-48c8-44c7-b4e3-5d5dded36b28",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. By design the validation and testing splits are nearly equivalent in size. This is a direct consequence of specifying the `test_split_frac` and `val_split_frac` when creating the splits with `train_test_split()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc5cee6-d5c8-409f-a853-07fe7fab9656",
   "metadata": {},
   "source": [
    "### Create Data Splits from Training Split, for NLP Model Development (to assign sentiment labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34197510-a308-4055-9b85-668ac7e2d80a",
   "metadata": {},
   "source": [
    "We will now draw a random sample from the training split to use in NLP (transformer) model fine-tuning in order to label the tweets with a sentiment (i.e. in order to extract the sentiment of the text in the tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ccf837-04e7-4678-8088-4cdb85e91885",
   "metadata": {},
   "source": [
    "First, we'll define the fraction of the training split to be used in NLP model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906c4982-5e4f-4416-a607-e09434d510b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.98 s, sys: 648 ms, total: 5.63 s\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp_sample_size = num_sampled_tweets / len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a80d7a-215b-4675-9447-e11212fb375b",
   "metadata": {},
   "source": [
    "Next, we'll extract a sample of the training data corresponding to this fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2d5fdd-b6d0-45ff-9230-52c984becb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.32 s, sys: 568 ms, total: 5.89 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train_sample = (\n",
    "    df_train.sample(frac=nlp_sample_size, random_state=88)\n",
    "    .compute()\n",
    "    .sort_values(by=[\"created_at\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a6d9b-7d9d-4c18-a02c-afac6981fe4b",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The sample is small enough that it fits in memory and so we don't need to use a big data framework to hold its contents. So, we call `.compute()` to bring this sample into memory and we can use in-memory tools (below) for creating data splits from this sample.\n",
    "2. Before creating the data splits for ML model development, the data was sorted by `datetime` when the tweet was posted (i.e. sorted by the `created_at` column). In order to create the splits for NLP model development in a way that is consistent with how the data splits were created for ML model development, after drawing the random sample, we sort the sampled data by the same `created_at` column before random splits will be created next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0ad8a-f131-45d9-98c1-1f8f67f57827",
   "metadata": {},
   "source": [
    "Tweets might be created at the same timestamp and so duplicated values are possible in this column, meaning that unique values in this column will be less than the total number of tweets in the data (including in the sampled data). Tweet IDs are unique for each tweet so the number of unique values in the `id` column will match the number of tweets in the data. These are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ba7fc7-75d2-44a1-90de-c5d2688e8673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs in sampled data = 10,001\n",
      "Number of unique creation datetimes in sampled data = 9,912\n",
      "Number of rows in sampled data = 10,001\n",
      "CPU times: user 6.13 ms, sys: 281 µs, total: 6.41 ms\n",
      "Wall time: 5.28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\n",
    "    f\"Number of unique IDs in sampled data = {df_train_sample['id'].nunique():,}\\n\"\n",
    "    f\"Number of unique creation datetimes in sampled data = {df_train_sample['created_at'].nunique():,}\\n\"\n",
    "    f\"Number of rows in sampled data = {len(df_train_sample):,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827db55-a575-440f-9d34-848611bc1c34",
   "metadata": {},
   "source": [
    "We'll now create random training, validation and testing splits from the sampled data, which will be used during NLP model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427f4896-5bb1-458d-9342-646eeb2d0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp_train_val, df_nlp_test = sk_train_test_split(\n",
    "    df_train_sample, test_size=test_split_frac, random_state=88\n",
    ")\n",
    "df_nlp_train, df_nlp_val = sk_train_test_split(\n",
    "    df_nlp_train_val, test_size=test_split_frac, random_state=88\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32c249-cb3b-45e9-9c97-68daa4c76472",
   "metadata": {},
   "source": [
    "## Export All Data Splits to S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb22c0-f85a-4f9c-919b-49a9d4c0e770",
   "metadata": {},
   "source": [
    "Get the start date for making inference with the trained ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc6a8c0-7181-45b8-b97d-9aa485355fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220110_000000\n"
     ]
    }
   ],
   "source": [
    "inference_start_date_str = (\n",
    "    inference_start_date.replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"_\")\n",
    ")\n",
    "print(inference_start_date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667d0177-f62c-4794-8705-4105220c041b",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The inference start date is used in file naming as a crude way to version data used in each round of ML model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c76b0a-1225-4dde-8caa-1097c8c86974",
   "metadata": {},
   "source": [
    "All data spits for ML model development will now be saved to a separate `.parquet` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c187cdb-ac43-46ba-a71c-41432b1acbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 170,037 rows to datasets/twitter/kinesis-demo/processed/splits/train__inference_starts_20220110_000000.parquet.gzip on S3\n",
      "Exported 28,361 rows to datasets/twitter/kinesis-demo/processed/splits/val__inference_starts_20220110_000000.parquet.gzip on S3\n",
      "Exported 28,249 rows to datasets/twitter/kinesis-demo/processed/splits/test__inference_starts_20220110_000000.parquet.gzip on S3\n",
      "CPU times: user 43.7 s, sys: 3.47 s, total: 47.2 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for split_name, df_split_to_export in zip(\n",
    "    [\"train\", \"val\", \"test\"], [df_train, df_val, df_test]\n",
    "):\n",
    "    fname = f\"{split_name}__inference_starts_{inference_start_date_str}.parquet.gzip\"\n",
    "    prefix = f\"{path_to_folder[1:]}processed/splits/{fname}\"\n",
    "    split_filepath = f\"s3://{s3_bucket_name}/{prefix}\"\n",
    "    df_split_to_export.to_parquet(\n",
    "        split_filepath,\n",
    "        write_index=False,\n",
    "        compression='gzip',\n",
    "        storage_options={\n",
    "            \"key\": session.get_credentials().access_key,\n",
    "            \"secret\": session.get_credentials().secret_key,\n",
    "        },\n",
    "    )\n",
    "    print(f\"Exported {len(df_split_to_export):,} rows to {prefix} on S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eea592-4113-4af1-beb6-a59b5bfaaa5c",
   "metadata": {},
   "source": [
    "All sampled data spits for NLP model development will now be saved to a separate `.CSV` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7f65ad1-e3be-4553-a0b6-604efe453eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 7,656 rows to datasets/twitter/kinesis-demo/processed/nlp_splits/train_nlp__inference_starts_20220110_000000.csv.zip on S3\n",
      "Exported 1,094 rows to datasets/twitter/kinesis-demo/processed/nlp_splits/val_nlp__inference_starts_20220110_000000.csv.zip on S3\n",
      "Exported 1,251 rows to datasets/twitter/kinesis-demo/processed/nlp_splits/test_nlp__inference_starts_20220110_000000.csv.zip on S3\n",
      "CPU times: user 885 ms, sys: 4.4 ms, total: 890 ms\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for split_name, df_split_to_export in zip(\n",
    "    [\"train_nlp\", \"val_nlp\", \"test_nlp\"],\n",
    "    [df_nlp_train, df_nlp_val, df_nlp_test],\n",
    "):\n",
    "    fname = f\"{split_name}__inference_starts_{inference_start_date_str}.csv.zip\"\n",
    "    prefix = f\"{path_to_folder[1:]}processed/nlp_splits/{fname}\"\n",
    "    split_filepath = f\"s3://{s3_bucket_name}/{prefix}\"\n",
    "    df_split_to_export.to_csv(\n",
    "        split_filepath,\n",
    "        index=False,\n",
    "        storage_options={\n",
    "            \"key\": session.get_credentials().access_key,\n",
    "            \"secret\": session.get_credentials().secret_key,\n",
    "        },\n",
    "    )\n",
    "    print(f\"Exported {len(df_split_to_export):,} rows to {prefix} on S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e3f200-cd55-429e-9212-9e7b0c911ead",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b63005-1934-433f-91d3-b649dab40b44",
   "metadata": {},
   "source": [
    "<span style=\"float:left;\">\n",
    "    <a href=\"./4_process_data.ipynb\"><< 4 - Data Processing</a>\n",
    "</span>\n",
    "\n",
    "<span style=\"float:right;\">\n",
    "    <a href=\"./6_nlp_labeling.ipynb\">6 - NLP-based Labeling >></a>\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark:Python",
   "language": "python",
   "name": "conda-env-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
